{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "38234303-bc10-48fd-81cc-0cca4fd068cf",
   "metadata": {},
   "source": [
    "#Task 1: Titanic Survival Prediction\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8ef25a-93e3-4007-99d1-0f12c7f66b0a",
   "metadata": {},
   "source": [
    "Develop a machine learning model to predict whether a passenger survived the Titanic disaster. \n",
    "• Dataset includes features like age, gender, ticket class, fare, cabin information etc. \n",
    "• Handle missing values, encode categorical variables, and normalize numerical data effectively. \n",
    "• Evaluate model performance using accuracy, precision, etc. \n",
    "• Expected outcome: A well-trained classification model with strong survival prediction accuracy.\n",
    "• Submit a GitHub repository with structured code, preprocessing steps, model selection, and performance analysis in README\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e1d0e878-5053-4f6e-98d9-1db6e670bfcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "031c24fb-4062-4a8a-bb67-e88ddf3d7f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loading the dataset\n",
    "data = pd.read_csv(\"titanic_dataset.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "66d6449e-a089-43a1-8a2c-cffe9ddfce40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# preprocessing\n",
    "\n",
    "# stp1 determine number of missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f51bab50-9392-4095-8edb-0cf95ca90b96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Cabin(categorical variable) we can convert it to numerical but as it not necessary for given specific task thus conversion \\nis skiped\\n'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# determing the type before handling null values \n",
    "data.dtypes\n",
    "data.head()\n",
    "\n",
    "# Drop unneeded columns\n",
    "data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)\n",
    "''' Cabin(categorical variable) we can convert it to numerical but as it not necessary for given specific task thus conversion \n",
    "is skiped\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "559e227e-2d75-46e9-82ea-109bd2c4f1ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      S\n",
       "1      C\n",
       "2      S\n",
       "3      S\n",
       "4      S\n",
       "      ..\n",
       "886    S\n",
       "887    S\n",
       "888    S\n",
       "889    C\n",
       "890    Q\n",
       "Name: Embarked, Length: 891, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#stp 2: Fill missing values of Age   and fare by meadian\n",
    "data['Age'] = data['Age'].fillna(data['Age'].median())\n",
    "\n",
    "\n",
    "# Fill missing Embarked values with most common value\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adcc0533-c1a7-4190-b714-d406b634070d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Survived    0\n",
       "Pclass      0\n",
       "Sex         0\n",
       "Age         0\n",
       "SibSp       0\n",
       "Parch       0\n",
       "Fare        0\n",
       "Embarked    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48bc4a74-4cd4-40b9-892b-76dd91039c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare',\n",
       "       'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "34048c26-d8dd-44a2-8993-c6b49aed887f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X columns: ['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Create feature matrix and target vector\n",
    "X = data.drop('Survived', axis=1)  # Simply drop the target column\n",
    "y = data['Survived']\n",
    "# Print to verify what columns we have\n",
    "print(\"X columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fc748be0-bd33-453d-ba2c-29e398c7290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Define feature columns based on what's actually in the data\n",
    "# Let's autodetect numeric and categorical columns\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3f8ae583-fc14-4fc1-bdf2-287eb512a17e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n",
      "Categorical features: ['Sex', 'Embarked']\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Define feature columns based on what's actually in the data\n",
    "# Let's autodetect numeric and categorical columns\n",
    "num_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "cat_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(\"Numeric features:\", num_features)\n",
    "print(\"Categorical features:\", cat_features)\n",
    "\n",
    "# Step 4: Build preprocessing pipeline\n",
    "num_transformer = StandardScaler()\n",
    "cat_transformer = OneHotEncoder(drop='first', handle_unknown='ignore')\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "], remainder='passthrough')  # This will keep any columns we didn't explicitly transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "255ed982-b052-4878-ae05-9d166bb0f6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Step 5: Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "873e0cca-4141-4ec8-a8c6-c7ee38a57f71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    1\n",
      "Name: Sex, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Assuming 'Sex' is a column in your DataFrame X\n",
    "le = LabelEncoder()\n",
    "X['Sex'] = le.fit_transform(X['Sex'])  # Transforms 'male' and 'female' into 0 and 1\n",
    "\n",
    "# Check the transformation\n",
    "print(X['Sex'].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8e920137-3cb7-4b97-adc9-8d29405317fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logistic Regression Performance:\n",
      "Accuracy: 0.8101\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.86      0.84       105\n",
      "           1       0.79      0.74      0.76        74\n",
      "\n",
      "    accuracy                           0.81       179\n",
      "   macro avg       0.81      0.80      0.80       179\n",
      "weighted avg       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[90 15]\n",
      " [19 55]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Random Forest Performance:\n",
      "Accuracy: 0.8212\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.87      0.85       105\n",
      "           1       0.80      0.76      0.78        74\n",
      "\n",
      "    accuracy                           0.82       179\n",
      "   macro avg       0.82      0.81      0.81       179\n",
      "weighted avg       0.82      0.82      0.82       179\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[91 14]\n",
      " [18 56]]\n",
      "\n",
      "==================================================\n",
      "\n",
      "Cross-validation scores (Logistic Regression):\n",
      "CV Accuracy: 0.7912 ± 0.0185\n",
      "\n",
      "Cross-validation scores (Random Forest):\n",
      "CV Accuracy: 0.8137 ± 0.0191\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "log_reg_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(max_iter=1000, random_state=42))\n",
    "])\n",
    "log_reg_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Random Forest\n",
    "rf_pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Step 7: Make predictions\n",
    "y_pred_log_reg = log_reg_pipeline.predict(X_test)\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# Step 8: Evaluate models\n",
    "print(\"\\nLogistic Regression Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_log_reg))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_log_reg))\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"Random Forest Performance:\")\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred_rf))\n",
    "\n",
    "# Optional: Cross-validation for more robust evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "print(\"Cross-validation scores (Logistic Regression):\")\n",
    "cv_scores_log_reg = cross_val_score(log_reg_pipeline, X, y, cv=5)\n",
    "print(f\"CV Accuracy: {cv_scores_log_reg.mean():.4f} ± {cv_scores_log_reg.std():.4f}\")\n",
    "\n",
    "print(\"\\nCross-validation scores (Random Forest):\")\n",
    "cv_scores_rf = cross_val_score(rf_pipeline, X, y, cv=5)\n",
    "print(f\"CV Accuracy: {cv_scores_rf.mean():.4f} ± {cv_scores_rf.std():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb10b09-6e81-4459-bd51-da80a8420e55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6888394-ceea-48c0-9251-24635374bd23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
